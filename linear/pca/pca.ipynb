{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2381cd-f095-49bd-98b7-7684cd380268",
   "metadata": {},
   "source": [
    "### Implementation of Principal Components Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e03c3a-ab80-4daa-abf5-9c4ff9087e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "51993765-bfa6-461a-8d23-02666e534bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X, dim):\n",
    "    \"\"\" Dimensionalty reduction with PCA.\n",
    "\n",
    "    Keyword arguments:\n",
    "    X -- Data matrix with M rows (observations) and N columns (features)\n",
    "    dim -- Reduced number of dimensions\n",
    "    \"\"\"\n",
    "    \n",
    "    # M observations, N features    \n",
    "    M = X.shape[0]\n",
    "    N = X.shape[1]\n",
    "\n",
    "    # Step 1: Calculate empirical mean along each observation and substract it from each value of X\n",
    "    mu = np.mean(X, 0)\n",
    "    X0 = X - mu\n",
    "    \n",
    "    # Check shape of X\n",
    "    # If M <= N, use the eigendecomposition of the covariance matrix\n",
    "    if M <= N:\n",
    "\n",
    "        print(f\"Eigendecomposition is used as n_observations ({M}) <= n_features ({N})\")\n",
    "        \n",
    "        # Step 2a: Find the empirical covariance matrix\n",
    "        C = (1 / M) * X0.T @ X0\n",
    "        \n",
    "        # Step 2b: Compute the eigenvalues and eigenvectors of C and sort them\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(C)\n",
    "        \n",
    "        # Step 2c: Order eigenvalues and corresponding left eigenvectors in descending order, select terms from one to selected dimension\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues_sorted = eigenvalues[idx]\n",
    "        eigenvalues_dim = eigenvalues_sorted[0:dim]\n",
    "        eigenvectors_sorted = eigenvectors[:,idx]\n",
    "        eigenvectors_dim = eigenvectors_sorted[:,0:dim]\n",
    "        \n",
    "        # Step 2d: Apply projection and obtain dimensionality reduction\n",
    "        Y = X0 @ eigenvectors_dim\n",
    "        \n",
    "        return eigenvalues_sorted, eigenvectors_sorted, Y\n",
    "\n",
    "    # If M>n, use the SVD of the centered data matrix\n",
    "    else:\n",
    "\n",
    "        print(f\"SVD is used as n_observations ({M}) > n_features ({N})\")\n",
    "        \n",
    "        # Step 2a: Compute the singular value decomposition of X0 (already ordered)\n",
    "        U, S, Vh = np.linalg.svd(X0, full_matrices=True)\n",
    "\n",
    "        # Step 2b: Select terms from one to selected dimension\n",
    "        singvalues_dim = S[0:dim]\n",
    "        singvectors_dim = U[:,0:dim]\n",
    "        \n",
    "        # Step 2c: Apply projection and obtain dimensionality reduction\n",
    "        Y = singvectors_dim @ np.diag(singvalues_dim) \n",
    "\n",
    "        return singvalues_dim, singvectors_dim, Y\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
